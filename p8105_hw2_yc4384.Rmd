---
title: "p8105_hw2_yc4384"
author: "Yangyang Chen"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(dplyr)
library(lubridate)
library(tools)
```

## Problem 1

**First:**

* Clean the data in `pols-month.csv`. 
* Use `separate()` to break up the variable `mon` into integer variables `year`, `month`, and `day`.
* Replace month number with month name 
* Create a `president` variable taking values `gop` and `dem`.
* Remove `prez_dem` and `prez_gop`; and remove the `day` variable.
```{r}
pols_df = 
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day")) |> 
  mutate(month = month.abb[as.numeric(month)]) |> 
  mutate(president = gov_dem) |> 
  select(-c(prez_dem,prez_gop)) |> 
  select(-day) 
```

**Second:** 

* Clean the data in snp.csv using a similar process to the above.
* Arrange according to year and month.
* Organize so that `year` and `month` are the leading columns.
```{r}
snp_df = 
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  mutate(date = mdy(date)) |> 
  separate(date, into = c("year", "month", "day")) |> 
  mutate(month = month.abb[as.numeric(month)]) |> 
  mutate(year = ifelse(as.numeric(year) >= 2050 & as.numeric(year)<= 2068, as.numeric(year) - 100, as.numeric(year))) |> 
  select(-day,) |> 
  mutate(year = as.character(year)) |> 
  relocate(year, month)
```

**Third:** 

* Tidy the unemployment data so that it can be merged with the previous datasets. 
* This process will involve switching from “wide” to “long” format.
* Ensuring that key variables have the same name.
* Ensuring that key variables take the same values.

```{r}
unemploy_df = 
  read_csv("data/unemployment.csv") |> 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemploy_rate"
  ) |> 
  janitor::clean_names() |> 
  mutate(year = as.character(year)) |> 
  mutate(month = toTitleCase(month)) |> 
  relocate(year, month)
```

**Date Description:** 

* Join the datasets by merging snp into pols.
* Merging unemployment into the result.

```{r}
prob1_df = 
pols_df |>  
  left_join(snp_df, by = c("year", "month")) |> 
  left_join(unemploy_df, by = c("year", "month"))

```
* **`pols_df`** contains `r nrow(pols_df)` observations and `r ncol(pols_df)` variables, describing the number of national politicians who are democratic or republican at any given time.

* **snp_df** contains `r nrow(snp_df)` observations and `r ncol(snp_df)` variables, describing Standard & Poor’s stock market index (S&P), often used as a representative measure of stock market as a whole.

* **unemploy_df** contains `r nrow(unemploy_df)` observations and `r ncol(unemploy_df)` variables, describing the percentage of unemployment in each month of the associated year.

* **prob1_df** is the `r dim(prob1_df)[1]` * `r dim(prob1_df)[2]` dimension result dataset, which contains `r nrow(prob1_df)` observations and `r ncol(prob1_df)` variables. It ranges from `r range(prob1_df$year)[1]` to  `r range(prob1_df$year)[2]`. It's variable combined all key variables in **`pols_df`**, **snp_df** and **unemploy_df** datasets, including *`r colnames(prob1_df)`.* 


## Problem 2
```{r}
library(readxl)
```

**Dataset_1 - Mr. Trash Wheel:**

* Specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel`.

* Use reasonable variable names.

* Omit rows that do not include dumpster-specific data.

* Update the data to include a new `homes_powered` variable based on this calculation.

```{r}
trash_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", range = "A2:N586") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered_new = weight_tons*500/30) 
```


**Dataset_2 - Professor Trash Wheel:**

* Import, clean, and organize the data for Professor Trash Wheel.

```{r}
prof_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M108") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered_new = weight_tons*500/30) 
```

**Dataset_3 - Gwynnda Trash Wheel:**

* Import, clean, and organize the data for Gwynnda Trash Wheel.

```{r}
gwyn_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L157") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered_new = weight_tons*500/30) 
```

**Tidy Three Datasets and Combination:**

Tidy:

```{r}
trash_df = 
  trash_df |> 
  mutate(name = "Mr.Trash") |> # dumpster_Mr_Trash = c(1:nrow(trash_df)-1)
  select(-c(homes_powered)) |> 
  mutate(date = as.character(date)) |> 
  mutate(year = as.character(year)) |> 
  relocate(name, dumpster)
```

```{r}
prof_df =
  prof_df |> 
  mutate(name = "Prof.Trash") |> 
  select(-c(homes_powered)) |> 
  mutate(date = as.character(date)) |> 
  mutate(year = as.character(year)) |> 
  relocate(name, dumpster)
```

```{r}
gwyn_df =
  gwyn_df |> 
  mutate(name = "Gwynnda_Trash") |> 
  select(-c(homes_powered))|> 
  mutate(date = as.character(date)) |> 
  mutate(year = as.character(year)) |>   
  relocate(name, dumpster)
```

Combination:
```{r}
prob2_df = 
  trash_df |> 
  full_join(prof_df, by = c("name","dumpster","year","month","date","glass_bottles", "weight_tons","volume_cubic_yards", "plastic_bottles", "polystyrene","cigarette_butts", "homes_powered_new")) |> 
  full_join(gwyn_df, by = c("name","dumpster","year","month","date", "weight_tons","volume_cubic_yards", "plastic_bottles", "polystyrene","cigarette_butts","homes_powered_new")) |> 
  mutate(date = as.Date(date, "%Y-%m-%d")) |> 
  arrange(date) |> 
  relocate(name, dumpster) 
```

**Data Description:**

* **prob2_df** contains `r nrow(prob2_df)` observations and `r ncol(prob2_df)` variables. Its key variables are *`r colnames(prob2_df)`*. The total weight of trash collected by Professor Trash Wheel are `r sum(prof_df$weight_tons)`. The total number of cigarette butts collected by Gwynnda in July of 2021 is `r prob2_df |> filter(month == "July" & year == "2021" & name == "Gwynnda_Trash")  |> pull(cigarette_butts) |> sum()`



## Problem 3

1. `MCI_baseline` data:

* Import and tidy data: Factorize sex and change it to a binary variable:
```{r}

base_df = 
  read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate(
    sex = 
      case_match(
      sex,
      1 ~ "male",
      0 ~ "female"), 
    sex = as.factor(sex)) |> 
  mutate(
    apoe4 = 
      case_match(
      apoe4,
      1 ~ "yes",
      0 ~ "no"), 
    sex = as.factor(sex)) 
```

**Filter:** Participants whose age of onset were before baseline time: 
```{r}
  not_free_df = base_df |> filter(age_at_onset != "." & current_age > age_at_onset) 
  not_free_df
```
Delete them in baseline dataset:
```{r}
  base_tidy_df = base_df  |> filter(!base_df$id %in% not_free_df$id)
```



**Data Pre-processing:**

* Step 1: Transformed binary variable of `sex` and `apoe4` to character variables.

* Step 2: Filtered participant who are free of MCI values in `age_at_onset`.

**Features of dataset `base_df`:**

* `base_df` dataset contains `r read_csv("data/MCI_baseline.csv", skip = 1) |> ncol()` key variables, including *`r read_csv("data/MCI_baseline.csv", skip = 1) |> janitor::clean_names() |> colnames()`*. 

* There are `r read_csv("data/MCI_baseline.csv", skip = 1) |> nrow()` participants were recruited, and of these `r read_csv("data/MCI_baseline.csv", skip = 1) |> janitor::clean_names() |> filter(age_at_onset != "." ) |> nrow()` develop MCI. 

* The average baseline age is `r read_csv("data/MCI_baseline.csv", skip = 1) |> janitor::clean_names() |> pull(current_age)  |> mean()`. 

* The proportion of women in the study are APOE4 carriers: `r base_tidy_df |> filter(sex == "female" & apoe4 == "yes")|> nrow() / base_tidy_df |> filter(sex == "female") |> nrow()`, 

II. Import, clean and tidy `mci_amyloid` data:

* Change error character type "Na" values into NA type.

* Modify `study_id` to `id` to ensure naming consistency.
```{r}
amy_df = 
  read_csv("data/mci_amyloid.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate( 
    baseline = replace(baseline, baseline == "Na", NA)
  )|> 
   mutate( 
    time_2 = replace(time_2, time_2 == "Na", NA)
  ) |> 
  mutate( 
    time_4 = replace(time_4, time_4 == "Na", NA)
  ) |> 
  mutate( 
    time_6 = replace(time_6, time_6 == "Na", NA)
  ) |> 
  mutate( 
    time_8 = replace(time_8, time_8 == "Na", NA)
  ) |> 
  mutate(id = study_id) |> 
  select(-study_id) |> 
  relocate(id)
```

**Fix a problem:** As time_# is speading across five columns, which corresponding to five observation times, we should fix it using `pivot_longer`:

```{r}
amy_tidy_data = 
  pivot_longer(
    amy_df,
    baseline:time_8,
    names_to = "time_length",
    values_to = "time_value"
  )
```

**`amy_tidy_data`** is a `r amy_tidy_data |> nrow()` *  `r amy_tidy_data |> ncol()` dataframe, containing `r amy_tidy_data |> ncol()` key variables, including *`r amy_tidy_data |> colnames()`.*

3. Check participants only aopear in the baseline or amyloid datasets:

```{r}

only_in_base = setdiff(base_df$id, amy_tidy_data$id)
only_in_base 
```
The participants `r only_in_base ` only appeared in the baseline data probably because they decided to move to a new location from which they cannot easily reach the study center.
```{r}
only_in_amyloid = setdiff(amy_tidy_data$id, base_df$id)
only_in_amyloid
```
The participants `r only_in_amyloid` only appeared in the amyloid data probably because they entered the study after few time from the baseline time.

```{r}
prob3_df = inner_join(base_tidy_df, amy_tidy_data, by = "id")
```
**Describing resulting data:**

* The resulting dataframe **prob3_df** has `r nrow(prob3_df)` observations with `r ncol(prob3_df)`
 variables, which includes *`r colnames(prob3_df)`*.

4. Export data into data directory:

```{r}
file_path = file.path("data", "MCI_Onset_Records.csv")
write.csv(prob3_df, file = file_path, row.names = TRUE)
```

